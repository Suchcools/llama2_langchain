{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Add Huggingface Transformers and LLaMA Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 install hf transformers\n",
    "    git clone https://github.com/huggingface/transformers.git\n",
    "    cd transformers\n",
    "    pip install ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Transcript LLaMA Weight to HF format\n",
    "    # 7B\n",
    "    python /home/linjw/codebase/preaction/3rdparty/transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py --input_dir /home/linjw/codebase/preaction/data/gpt/llama_weights/LLaMA_ori/ --model_size 7B --output_dir /home/shizhenkun/codebase/preaction/data/gpt/llama_weights/llama-7b-hf\n",
    "\n",
    "    # 13B\n",
    "    python /home/linjw/codebase/preaction/3rdparty/transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py --input_dir /home/linjw/codebase/preaction/data/gpt/llama_weights/LLaMA_ori/ --model_size 13B --output_dir /home/shizhenkun/codebase/preaction/data/gpt/llama_weights/llama-13b-hf\n",
    "\n",
    "    # 30B\n",
    "    python /home/linjw/codebase/preaction/3rdparty/transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py --input_dir /home/linjw/codebase/preaction/data/gpt/llama_weights/LLaMA_ori/ --model_size 30B --output_dir /home/shizhenkun/codebase/preaction/data/gpt/llama_weights/llama-30b-hf\n",
    "\n",
    "    #65B\n",
    "    python /home/linjw/codebase/preaction/3rdparty/transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py --input_dir /home/linjw/codebase/preaction/data/gpt/llama_weights/LLaMA_ori/ --model_size 65B --output_dir /home/shizhenkun/codebase/preaction/data/gpt/llama_weights/llama-65b-hf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add Vicuna Lora Weight to LLaMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # 13B\n",
    "    python -m fastchat.model.apply_delta \\\n",
    "        --base /home/linjw/codebase/preaction/data/gpt/llama_weights/llama-13b-hf \\\n",
    "        --target /home/linjw/codebase/preaction/data/gpt/fastchat_weight/vicuna/vicuna-13b \\\n",
    "        --delta /home/linjw/codebase/preaction/data/gpt/vicuna/vicuna-13b-delta-v1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Start Vicuna with Web Sever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Single Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    conda activate preaction\n",
    "    cd /home/linjw/codebase/preaction/3rdparty/FastChat\n",
    "\n",
    "    #start controller\n",
    "    python -m fastchat.serve.controller --host 0.0.0.0 --port 10002\n",
    "\n",
    "    #load model\n",
    "    # python -m fastchat.serve.model_worker --model-path /home/linjw/codebase/preaction/data/gpt/fastchat_weight/vicuna/vicuna-13b  --controller http://127.0.0.1:10002 --num-gpus 1\n",
    "    python -m fastchat.serve.model_worker --model-path /home/linjw/codebase/preaction/data/gpt/fastchat_weight/vicuna/vicuna-7b  --controller http://127.0.0.1:10002 --num-gpus 1\n",
    "    #start web-ui\n",
    "    python -m fastchat.serve.gradio_web_server --controller http://127.0.0.1:10002 --host banana.tibd.net --model-list-mode reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train Your Own Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    torchrun --nproc_per_node=8 --master_port=20001 fastchat/train/train_mem.py \\\n",
    "        --model_name_or_path /home/linjw/codebase/preaction/data/gpt/fastchat_weight/vicuna/vicuna-7b  \\\n",
    "        --data_path /home/linjw/codebase/preaction/3rdparty/FastChat/playground/data/dummy.json \\\n",
    "        --bf16 True \\\n",
    "        --output_dir /home/linjw/codebase/preaction/data/gpt/finetuned/vicuna_dummy \\\n",
    "        --num_train_epochs 3 \\\n",
    "        --per_device_train_batch_size 2 \\\n",
    "        --per_device_eval_batch_size 2 \\\n",
    "        --gradient_accumulation_steps 16 \\\n",
    "        --evaluation_strategy \"no\" \\\n",
    "        --save_strategy \"steps\" \\\n",
    "        --save_steps 1200 \\\n",
    "        --save_total_limit 10 \\\n",
    "        --learning_rate 2e-5 \\\n",
    "        --weight_decay 0. \\\n",
    "        --warmup_ratio 0.03 \\\n",
    "        --lr_scheduler_type \"cosine\" \\\n",
    "        --logging_steps 1 \\\n",
    "        --fsdp \"full_shard auto_wrap\" \\\n",
    "        --fsdp_transformer_layer_cls_to_wrap 'LlamaDecoderLayer' \\\n",
    "        --tf32 True \\\n",
    "        --model_max_length 2048 \\\n",
    "        --gradient_checkpointing True \\\n",
    "        --lazy_preprocess True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Using Alpaca Lora to Train and Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    CUDA_VISIBLE_DEVICES=1 python finetune.py \\\n",
    "    --base_model '/home/linjw/codebase/FastChat/data/fastchat_weight/vicuna' \\\n",
    "    --data_path '/home/linjw/codebase/FastChat/data/corpus/alpaca_data_cleaned_archive.json' \\\n",
    "    --output_dir '/home/linjw/codebase/FastChat/data/finetuned/bio' \\\n",
    "    --batch_size 128 \\\n",
    "    --micro_batch_size 4 \\\n",
    "    --num_epochs 3 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --cutoff_len 512 \\\n",
    "    --val_set_size 2000 \\\n",
    "    --lora_r 8 \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0.05 \\\n",
    "    --lora_target_modules '[q_proj,k_proj,v_proj,o_proj]' \\\n",
    "    --train_on_inputs \\\n",
    "    --group_by_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
